{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1)\n",
    "from keras import backend as K\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example input ('folder1','folder2')\n",
      "example input ('folder1','folder2')\n"
     ]
    }
   ],
   "source": [
    "# preprocessing, move files to current project folder use soft link to faster and reduce space usage\n",
    "\n",
    "keras_download_train = '/home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/train'\n",
    "keras_download_test = '/home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/test'\n",
    "train_filenames_list = os.listdir(keras_download_train)\n",
    "\n",
    "train_cat = list(filter(lambda x:x[:3] == 'cat', train_filenames_list))\n",
    "train_dog = list(filter(lambda x:x[:3] == 'dog', train_filenames_list))\n",
    "\n",
    "\n",
    "def check_make_dir(*dirs):\n",
    "    print(\"example input ('folder1','folder2')\")\n",
    "    for count,dirname in enumerate(dirs):\n",
    "        if os.path.exists(dirname) and os.path.isdir(dirname):\n",
    "            shutil.rmtree(dirname)\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "check_make_dir('train2','train2/cat','train2/dog','test2')\n",
    "\n",
    "check_make_dir('train','train/cat','train/dog','test','validation','validation/cat','validation/dog')\n",
    "        \n",
    "        \n",
    "os.symlink(keras_download_test, 'test2/test')\n",
    "\n",
    "for filename in train_cat:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'train2/cat/'+filename)\n",
    "\n",
    "for filename in train_dog:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'train2/dog/'+filename)\n",
    "    \n",
    "\n",
    "os.symlink(keras_download_test, 'test/test')\n",
    "\n",
    "for filename in train_cat[:8500]:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'train/cat/'+filename)\n",
    "\n",
    "for filename in train_dog[:8500]:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'train/dog/'+filename)\n",
    "    \n",
    "for filename in train_cat[8500:]:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'validation/cat/'+filename)\n",
    "\n",
    "for filename in train_dog[8500:]:\n",
    "    os.symlink(keras_download_train+'/'+filename, 'validation/dog/'+filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_shape(img_width, img_height):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3,img_width,img_height)\n",
    "    else:\n",
    "        input_shape = (img_width,img_height,3)\n",
    "    return input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image.py:959: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 20727s 829ms/step\n",
      "12500/12500 [==============================] - 10371s 830ms/step\n"
     ]
    }
   ],
   "source": [
    "# prepare image tensor\n",
    "\n",
    "image_gen = ImageDataGenerator(featurewise_center=True,fill_mode='constant', \n",
    "                               cval=0, horizontal_flip=True, rotation_range=20, shear_range=0.2)\n",
    "\n",
    "train_gen = image_gen.flow_from_directory(\"train2\", (299, 299), shuffle=False, \n",
    "                                    batch_size=32, class_mode=None)\n",
    "\n",
    "test_gen = image_gen.flow_from_directory(\"test2\", (299, 299), shuffle=False, \n",
    "                                         batch_size=32, class_mode=None)\n",
    "\n",
    "train_filenames = train_gen.filenames\n",
    "train_nb_samples = len(train_filenames)\n",
    "\n",
    "test_filenames = test_gen.filenames\n",
    "test_nb_samples = len(test_filenames)\n",
    "\n",
    "\n",
    "# define professor X\n",
    "x = Input((299, 299, 3))\n",
    "x = InceptionResNetV2(input_tensor=x, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "\n",
    "train = x.predict_generator(train_gen, steps=train_nb_samples, \n",
    "                                            verbose=1)\n",
    "\n",
    "test = x.predict_generator(test_gen, steps=test_nb_samples, \n",
    "                                           verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't prepare for writing data (file write failed: time = Thu Aug  2 10:03:41 2018\n, filename = 'gap_InceptionResNetV2.h5', file descriptor = 63, errno = 28, error message = 'No space left on device', buf = 0x7ff4c6973fb0, total write size = 1868353632, bytes this sub-write = 1868353632, bytes actually written = 18446744073709551615, offset = 10408222720)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-58f3123af416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gap_{0}.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'InceptionResNetV2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdset_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't prepare for writing data (file write failed: time = Thu Aug  2 10:03:41 2018\n, filename = 'gap_InceptionResNetV2.h5', file descriptor = 63, errno = 28, error message = 'No space left on device', buf = 0x7ff4c6973fb0, total write size = 1868353632, bytes this sub-write = 1868353632, bytes actually written = 18446744073709551615, offset = 10408222720)"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"gap_{0}.h5\".format('InceptionResNetV2')) as h:\n",
    "    h.create_dataset(\"train\", data=train)\n",
    "    h.create_dataset(\"test\", data=test)\n",
    "    h.create_dataset(\"label\", data=train_gen.classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9.7G\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  19K Aug  1 23:58 Untitled.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu    6 Aug  1 23:58 README.md\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  91K Aug  1 23:58 model.h5_save\r\n",
      "drwxrwxr-x 2 ubuntu ubuntu 4.0K Aug  1 23:58 \u001b[0m\u001b[01;34muda\u001b[0m/\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 112K Aug  1 23:58 sample_submission.csv\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 307K Aug  1 23:58 pred.csv\r\n",
      "drwxrwxr-x 4 ubuntu ubuntu 4.0K Aug  2 00:00 \u001b[01;34mtrain2\u001b[0m/\r\n",
      "drwxrwxr-x 2 ubuntu ubuntu 4.0K Aug  2 00:00 \u001b[01;34mtest2\u001b[0m/\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  14K Aug  2 09:52 graduation_project.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9.7G Aug  2 10:03 gap_InceptionResNetV2.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls -ltrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 272M Aug  1 23:47 \u001b[0m\u001b[01;31m/home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/test.zip\u001b[0m\u001b[K\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 544M Aug  1 23:47 \u001b[01;31m/home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/train.zip\u001b[0m\u001b[K\r\n"
     ]
    }
   ],
   "source": [
    "ls -ltrh /home/ubuntu/.kaggle/competitions/dogs-vs-cats-redux-kernels-edition/*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1G\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 294M May 25  2017 gap_Xception.h5\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu  74M May 25  2017 gap_VGG19.h5\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu  74M May 25  2017 gap_VGG16.h5\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 294M May 25  2017 gap_ResNet50.h5\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 294M May 25  2017 gap_InceptionV3.h5\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 2.8M Jul 18 02:00 Nvidia_Cloud_EULA.pdf\r\n",
      "drwxrwxr-x  5 ubuntu ubuntu 4.0K Jul 19 18:10 \u001b[0m\u001b[01;34mtutorials\u001b[0m/\r\n",
      "drwxrwxr-x  8 ubuntu ubuntu 4.0K Jul 19 18:10 \u001b[01;34mexamples\u001b[0m/\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 2.8K Jul 19 18:11 README\r\n",
      "drwxrwxr-x 24 ubuntu ubuntu 4.0K Jul 19 19:15 \u001b[01;34manaconda3\u001b[0m/\r\n",
      "drwxrwxr-x 10 ubuntu ubuntu 4.0K Jul 19 19:59 \u001b[01;34msrc\u001b[0m/\r\n",
      "-rw-rw-r--  1 ubuntu ubuntu 112K Aug  1 23:46 sample_submission.csv\r\n",
      "drwxrwxr-x  7 ubuntu ubuntu 4.0K Aug  2 10:07 \u001b[01;34muda\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -ltrh /home/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "stage2\n",
      "ResNet50\n",
      "stage3\n",
      "  290/25000 [..............................] - ETA: 1:00:45"
     ]
    }
   ],
   "source": [
    "\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    x = Input((height, width, 3))\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"train2\", image_size, shuffle=False, \n",
    "                                              batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(\"test2\", image_size, shuffle=False, \n",
    "                                             batch_size=16, class_mode=None)\n",
    "    print(\"stage2\")\n",
    "\n",
    "    #my add starts\n",
    "    train_filenames = train_generator.filenames\n",
    "    train_nb_samples = len(train_filenames)\n",
    "\n",
    "    test_filenames = test_generator.filenames\n",
    "    test_nb_samples = len(test_filenames)\n",
    "    \n",
    "    #my add finish\n",
    "    \n",
    "    print(\"{}\".format(MODEL.__name__))\n",
    "    print(\"stage3\")\n",
    "    \n",
    "    train = model.predict_generator(train_generator,steps=train_nb_samples,verbose=1)\n",
    "    test = model.predict_generator(test_generator,steps=test_nb_samples,verbose=1)\n",
    "    \n",
    "    print(\"stage4\")\n",
    "\n",
    "                                   \n",
    "    with h5py.File(\"gap_%s.h5\"%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "        \n",
    "write_gap(ResNet50, (224, 224), resnet50.preprocess_input)\n",
    "        \n",
    "'''\n",
    "write_gap(InceptionResNetV2, (299, 299), inception_resnet_v2.preprocess_input)\n",
    "\n",
    "\n",
    "write_gap(ResNet50, (224, 224), resnet50.preprocess_input)\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tf.ConfigProto( device_count = {'GPU':1,'CPU':4})\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11268157532926125419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"{}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"plz install gpu version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bdbb3f28c35d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gap_%s.h5\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16995 images belonging to 2 classes.\n",
      "Found 7999 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "img_width, img_height = 299,299\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(32,(3,3), input_shape=get_input_shape(img_width,img_height)))\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "base_model.add(Conv2D(32,(3,3)))\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "base_model.add(Conv2D(64,(3,3)))\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(64))\n",
    "base_model.add(Activation('relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Dense(1))\n",
    "base_model.add(Activation('sigmoid'))\n",
    "\n",
    "base_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "#seems rescale is very important.\n",
    "#image_gen = ImageDataGenerator(featurewise_center=False,fill_mode='nearest',\n",
    "#                               cval=0,horizontal_flip=True,rotation_range=20,shear_range=0.2,rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "image_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# validation_split=0.4, cval=0, fill_mode='constant'\n",
    "\n",
    "train_gen = image_gen.flow_from_directory(\"train\", (img_width,img_height), shuffle=True,interpolation='bicubic',\n",
    "                                    batch_size=16)# subset = \"training\",class_mode=\"categorical\"\n",
    "\n",
    "validation_gen = image_gen.flow_from_directory(\"validation\", (img_width,img_height), shuffle=False,interpolation='bicubic',\n",
    "                                    batch_size=16) # 'binary',\n",
    "\n",
    "test_gen = image_gen.flow_from_directory(\"test2\", (img_width,img_height), shuffle=False, \n",
    "                                         batch_size=8, class_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
